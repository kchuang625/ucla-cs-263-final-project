{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c85492b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch version 1.12.0+cu102 available.\n",
      "2023-06-04 12:29:03.262829: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-04 12:29:03.627829: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/lib64:\n",
      "2023-06-04 12:29:03.627878: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-04 12:29:05.440947: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/lib64:\n",
      "2023-06-04 12:29:05.441116: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/lib64:\n",
      "2023-06-04 12:29:05.441131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "TensorFlow version 2.11.0 available.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import emoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_metric\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe4c1a76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>rephrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>College is really difficult, expensive, tiring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not like when professors don‚Äôt write out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>I, at the bare minimum, wish companies actuall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today my pop-pop told me I was not ‚Äúforced‚Äù to...</td>\n",
       "      <td>1</td>\n",
       "      <td>Today my pop-pop told me I was not \"forced\" to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>I would say Ted Cruz is an asshole and doesn‚Äôt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>The population spike in Chicago in 9 months is...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>You'd think in the second to last English clas...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>I‚Äôm finally surfacing after a holiday to Scotl...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>Overheard as my 13 year old games with a frien...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3468 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  sarcastic  \\\n",
       "0     The only thing I got from college is a caffein...          1   \n",
       "1     I love it when professors draw a big question ...          1   \n",
       "2     Remember the hundred emails from companies whe...          1   \n",
       "3     Today my pop-pop told me I was not ‚Äúforced‚Äù to...          1   \n",
       "4     @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
       "...                                                 ...        ...   \n",
       "3463  The population spike in Chicago in 9 months is...          0   \n",
       "3464  You'd think in the second to last English clas...          0   \n",
       "3465  I‚Äôm finally surfacing after a holiday to Scotl...          0   \n",
       "3466  Couldn't be prouder today. Well done to every ...          0   \n",
       "3467  Overheard as my 13 year old games with a frien...          0   \n",
       "\n",
       "                                               rephrase  \n",
       "0     College is really difficult, expensive, tiring...  \n",
       "1     I do not like when professors don‚Äôt write out ...  \n",
       "2     I, at the bare minimum, wish companies actuall...  \n",
       "3     Today my pop-pop told me I was not \"forced\" to...  \n",
       "4     I would say Ted Cruz is an asshole and doesn‚Äôt...  \n",
       "...                                                 ...  \n",
       "3463                                                     \n",
       "3464                                                     \n",
       "3465                                                     \n",
       "3466                                                     \n",
       "3467                                                     \n",
       "\n",
       "[3468 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train/train.En.csv\")[[\"tweet\", \"sarcastic\", \"rephrase\"]]\n",
    "train_df[\"tweet\"] = train_df[\"tweet\"].fillna(\"\")\n",
    "train_df[\"rephrase\"] = train_df[\"rephrase\"].fillna(\"\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39158d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Size on the the Toulouse team, That pack is mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pinball!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So the Scottish Government want people to get ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>villainous pro tip : change the device name on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would date any of these men ü•∫</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>I‚Äôve just seen this and felt it deserved a Ret...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>Omg how an earth is that a pen !!! ü§°</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>Bringing Kanye and drake to a tl near you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>I love it when women are referred to as \"girl ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>The fact that people still don't get that you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sarcastic\n",
       "0     Size on the the Toulouse team, That pack is mo...          0\n",
       "1                                              Pinball!          0\n",
       "2     So the Scottish Government want people to get ...          1\n",
       "3     villainous pro tip : change the device name on...          0\n",
       "4                       I would date any of these men ü•∫          0\n",
       "...                                                 ...        ...\n",
       "1395  I‚Äôve just seen this and felt it deserved a Ret...          0\n",
       "1396               Omg how an earth is that a pen !!! ü§°          0\n",
       "1397          Bringing Kanye and drake to a tl near you          0\n",
       "1398  I love it when women are referred to as \"girl ...          1\n",
       "1399  The fact that people still don't get that you ...          1\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test/task_A_En_test.csv\")\n",
    "test_df[\"text\"] = test_df[\"text\"].fillna(\"\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffa80326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking /home/ray080186/.cache/huggingface/datasets/4c530db6524e184f3ae54c23f61ccff4ed3044ff6415e1e28d05618f6eb71752.f7b1a1b5c5768ef71463744e19ab26eb2bfa9b9d2ca9ece6a94ee05f37520247.py for additional imports.\n",
      "Found main folder for metric https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics/accuracy/accuracy.py at /home/ray080186/.cache/huggingface/modules/datasets_modules/metrics/accuracy\n",
      "Found specific version folder for metric https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics/accuracy/accuracy.py at /home/ray080186/.cache/huggingface/modules/datasets_modules/metrics/accuracy/618004201c82ad7cefba547c6116ab7245ee7ccf428d0b23483d20bcc118fb51\n",
      "Found script file from https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics/accuracy/accuracy.py to /home/ray080186/.cache/huggingface/modules/datasets_modules/metrics/accuracy/618004201c82ad7cefba547c6116ab7245ee7ccf428d0b23483d20bcc118fb51/accuracy.py\n",
      "Couldn't find dataset infos file at https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics/accuracy/dataset_infos.json\n",
      "Found metadata file for metric https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics/accuracy/accuracy.py at /home/ray080186/.cache/huggingface/modules/datasets_modules/metrics/accuracy/618004201c82ad7cefba547c6116ab7245ee7ccf428d0b23483d20bcc118fb51/accuracy.json\n",
      "Checking /home/ray080186/.cache/huggingface/datasets/9cf48e7430b438f6a92431a6dc5771d7cb22009fd56adce93f161414e4cd5345.3c9109dd58bcb3f88630a98de3b68825179bc84d0ae17a5f5ebc137fd0e7310e.py for additional imports.\n",
      "Found main folder for metric https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics/f1/f1.py at /home/ray080186/.cache/huggingface/modules/datasets_modules/metrics/f1\n",
      "Found specific version folder for metric https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics/f1/f1.py at /home/ray080186/.cache/huggingface/modules/datasets_modules/metrics/f1/9266b41af9f54f6ec149196b308e3c691a7da9e97256b7e926b564bfedfe3599\n",
      "Found script file from https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics/f1/f1.py to /home/ray080186/.cache/huggingface/modules/datasets_modules/metrics/f1/9266b41af9f54f6ec149196b308e3c691a7da9e97256b7e926b564bfedfe3599/f1.py\n",
      "Couldn't find dataset infos file at https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics/f1/dataset_infos.json\n",
      "Found metadata file for metric https://s3.amazonaws.com/datasets.huggingface.co/datasets/metrics/f1/f1.py at /home/ray080186/.cache/huggingface/modules/datasets_modules/metrics/f1/9266b41af9f54f6ec149196b308e3c691a7da9e97256b7e926b564bfedfe3599/f1.json\n"
     ]
    }
   ],
   "source": [
    "acc_metric = load_metric(\"accuracy\")\n",
    "f1_metric = load_metric(\"f1\")\n",
    "thd = 0.25\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    y_pred = torch.softmax(torch.FloatTensor(predictions), dim=1)[:, 1] > thd\n",
    "    scores = f1_metric.compute(predictions=y_pred, references=labels)\n",
    "    scores.update(acc_metric.compute(predictions=y_pred, references=labels))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84922a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = \"@user\" if t.startswith(\"@\") and len(t) > 1 else t\n",
    "        t = \"http\" if t.startswith(\"http\") else t\n",
    "        new_text.append(t)\n",
    "    return emoji.demojize(\" \".join(new_text), language=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee431695",
   "metadata": {},
   "source": [
    "### Fine-tuned Transformers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87e838",
   "metadata": {},
   "source": [
    "#### Customized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5c5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98565c5",
   "metadata": {},
   "source": [
    "#### Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcc12b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model_id=\"bert-base-cased\", seed=0):\n",
    "    print(f\"{model_id=}, {seed=}\")\n",
    "    \n",
    "    # set random seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # prepare training data\n",
    "    all_idxs = np.arange(len(train_df))\n",
    "    train_idxs, valid_idxs = get_train_test_indices(len(all_idxs), test_size=0.2)\n",
    "    train_idxs, valid_idxs = all_idxs[train_idxs], all_idxs[valid_idxs]\n",
    "    X_train = train_df[\"tweet\"].apply(preprocess).values[train_idxs]\n",
    "    X_valid = train_df[\"tweet\"].apply(preprocess).values[valid_idxs]\n",
    "    X_test = test_df[\"text\"].apply(preprocess).values\n",
    "    y_train = train_df[\"sarcastic\"].values[train_idxs]\n",
    "    y_valid = train_df[\"sarcastic\"].values[valid_idxs]\n",
    "    y_test = test_df[\"sarcastic\"].values\n",
    "    \n",
    "    # tokenize\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=512)\n",
    "    valid_encodings = tokenizer(list(X_valid), truncation=True, padding=True, max_length=512)\n",
    "    test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # prepare torch dataset\n",
    "    train_dataset = TweetDataset(train_encodings, y_train)\n",
    "    valid_dataset = TweetDataset(valid_encodings, y_valid)\n",
    "    test_dataset = TweetDataset(test_encodings, y_test)\n",
    "    \n",
    "    # fine-tune given transformer\n",
    "    batch_size = 16\n",
    "    gradient_accumulation_steps = 1\n",
    "    actual_batch_size = batch_size * gradient_accumulation_steps\n",
    "    n_epoch = 3\n",
    "    total_steps = round(len(y_train) / actual_batch_size / 4 * n_epoch)\n",
    "    warmup_steps = total_steps * 0.1\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"/tmp2/kch/cs263/final_project/models\",\n",
    "        learning_rate=1e-4,\n",
    "        num_train_epochs=n_epoch,                # total number of training epochs\n",
    "        per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        per_device_eval_batch_size=64,           # batch size for evaluation\n",
    "        warmup_steps=warmup_steps,               # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,                       # strength of weight decay\n",
    "        logging_dir=\"./logs\",                    # directory for storing logs\n",
    "        logging_steps=20,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        metric_for_best_model=\"f1\",\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_id,\n",
    "        num_labels=2,\n",
    "        ignore_mismatched_sizes=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
    "        args=training_args,                  # training arguments, defined above\n",
    "        train_dataset=train_dataset,         # training dataset\n",
    "        eval_dataset=valid_dataset,          # evaluation dataset\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    # evaluate\n",
    "    y_pred = trainer.predict(test_dataset)[0]\n",
    "    y_pred = torch.softmax(torch.FloatTensor(y_pred), dim=1)[:, 1] > thd\n",
    "    renamed_model_id = model_id.replace(\"/\", \"-\")\n",
    "    with open(f\"predictions/{renamed_model_id}_{seed}.npy\", \"wb\") as f:\n",
    "        np.save(f, y_pred.detach().cpu().numpy())\n",
    "    return f1_metric.compute(predictions=y_pred, references=y_test)[\"f1\"]\n",
    "\n",
    "\n",
    "def get_train_test_indices(n, test_size):\n",
    "    n_train = round(n * (1 - test_size))\n",
    "    all_idxs = list(range(n))\n",
    "    random.shuffle(all_idxs)\n",
    "    return all_idxs[:n_train], all_idxs[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4bf85b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id='brahimje/roberta-sarcasm-detection', seed=5497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.334300</td>\n",
       "      <td>0.224160</td>\n",
       "      <td>0.808864</td>\n",
       "      <td>0.900576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.216571</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.922190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.409479</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.913545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.83125).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.723\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.302206</td>\n",
       "      <td>0.756579</td>\n",
       "      <td>0.893372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.303708</td>\n",
       "      <td>0.783439</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.432010</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.904899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.7834394904458598).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.814\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.344700</td>\n",
       "      <td>0.304214</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.122900</td>\n",
       "      <td>0.341078</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.887608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.589276</td>\n",
       "      <td>0.742049</td>\n",
       "      <td>0.894813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.7777777777777777).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.805\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.316600</td>\n",
       "      <td>0.335125</td>\n",
       "      <td>0.752239</td>\n",
       "      <td>0.880403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.315779</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.890490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.435724</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.889049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.7888888888888889).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.742\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.289637</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.913545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.338509</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.359631</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.922190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.83125).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.846\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.243699</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.896254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.307271</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.912104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.416880</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.916427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.802721088435374).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.851\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.337600</td>\n",
       "      <td>0.226278</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.270989</td>\n",
       "      <td>0.810631</td>\n",
       "      <td>0.917867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.506164</td>\n",
       "      <td>0.773973</td>\n",
       "      <td>0.904899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.8106312292358805).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.814\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.318000</td>\n",
       "      <td>0.394379</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>0.876081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.325134</td>\n",
       "      <td>0.804805</td>\n",
       "      <td>0.906340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.533667</td>\n",
       "      <td>0.739274</td>\n",
       "      <td>0.886167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.8048048048048048).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.835\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.356200</td>\n",
       "      <td>0.257176</td>\n",
       "      <td>0.751092</td>\n",
       "      <td>0.835735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.274821</td>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.495957</td>\n",
       "      <td>0.765273</td>\n",
       "      <td>0.894813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.8228571428571427).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.761\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.301500</td>\n",
       "      <td>0.262244</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.896254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.315654</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.600567</td>\n",
       "      <td>0.736486</td>\n",
       "      <td>0.887608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8032786885245902).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.634\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.272094</td>\n",
       "      <td>0.771084</td>\n",
       "      <td>0.890490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.429100</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.887608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.488700</td>\n",
       "      <td>0.773770</td>\n",
       "      <td>0.900576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.7737704918032786).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.865\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.278300</td>\n",
       "      <td>0.213432</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.917867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.160500</td>\n",
       "      <td>0.229530</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.423286</td>\n",
       "      <td>0.794788</td>\n",
       "      <td>0.909222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8421052631578947).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.671\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 02:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.300400</td>\n",
       "      <td>0.323016</td>\n",
       "      <td>0.748466</td>\n",
       "      <td>0.881844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.388105</td>\n",
       "      <td>0.725552</td>\n",
       "      <td>0.874640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.724964</td>\n",
       "      <td>0.687285</td>\n",
       "      <td>0.868876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.7484662576687117).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.788\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 02:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.265271</td>\n",
       "      <td>0.819767</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.395622</td>\n",
       "      <td>0.761290</td>\n",
       "      <td>0.893372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.474066</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.896254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8197674418604651).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.706\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.253082</td>\n",
       "      <td>0.700696</td>\n",
       "      <td>0.814121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.268752</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.904899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.323700</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.920749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.8070175438596491).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.806\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>0.338049</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.913545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.284432</td>\n",
       "      <td>0.810289</td>\n",
       "      <td>0.914986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.522093</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.8102893890675242).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.762\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.318775</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.867435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.498897</td>\n",
       "      <td>0.739274</td>\n",
       "      <td>0.886167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.547034</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.887608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.75).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.845\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.288799</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.906340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.314139</td>\n",
       "      <td>0.824281</td>\n",
       "      <td>0.920749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.451897</td>\n",
       "      <td>0.804054</td>\n",
       "      <td>0.916427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.8242811501597445).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.753\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.311900</td>\n",
       "      <td>0.230537</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.311699</td>\n",
       "      <td>0.754839</td>\n",
       "      <td>0.890490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.517097</td>\n",
       "      <td>0.778878</td>\n",
       "      <td>0.903458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8191489361702128).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.596\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.338300</td>\n",
       "      <td>0.254454</td>\n",
       "      <td>0.781145</td>\n",
       "      <td>0.906340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>0.347925</td>\n",
       "      <td>0.771536</td>\n",
       "      <td>0.912104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.423547</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.919308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.7971014492753623).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.807\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.881844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>0.285506</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.913545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.480344</td>\n",
       "      <td>0.762264</td>\n",
       "      <td>0.909222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.7887323943661971).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.807\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.329600</td>\n",
       "      <td>0.373895</td>\n",
       "      <td>0.677165</td>\n",
       "      <td>0.881844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.240342</td>\n",
       "      <td>0.798762</td>\n",
       "      <td>0.906340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.307776</td>\n",
       "      <td>0.810289</td>\n",
       "      <td>0.914986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.8102893890675241).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.737\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>0.289672</td>\n",
       "      <td>0.743202</td>\n",
       "      <td>0.877522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.322105</td>\n",
       "      <td>0.723288</td>\n",
       "      <td>0.854467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.576093</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.893372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.743202416918429).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.708\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.266654</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.904899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.245823</td>\n",
       "      <td>0.831099</td>\n",
       "      <td>0.909222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.503670</td>\n",
       "      <td>0.774603</td>\n",
       "      <td>0.897695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.8310991957104557).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.71\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.329028</td>\n",
       "      <td>0.730496</td>\n",
       "      <td>0.890490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.416681</td>\n",
       "      <td>0.716312</td>\n",
       "      <td>0.884726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.422639</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.906340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.7719298245614035).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.823\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.305100</td>\n",
       "      <td>0.324348</td>\n",
       "      <td>0.741433</td>\n",
       "      <td>0.880403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.333139</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.890490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.640395</td>\n",
       "      <td>0.696296</td>\n",
       "      <td>0.881844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.7594936708860759).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.715\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 89/132 00:56 < 00:27, 1.55 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.289545</td>\n",
       "      <td>0.787671</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.132300</td>\n",
       "      <td>0.366023</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.899135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.7893175074183976).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.704\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 90/132 01:09 < 00:33, 1.26 it/s, Epoch 2.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.287400</td>\n",
       "      <td>0.249855</td>\n",
       "      <td>0.786280</td>\n",
       "      <td>0.883285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.147600</td>\n",
       "      <td>0.289041</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.8052805280528051).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.808\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.327100</td>\n",
       "      <td>0.299580</td>\n",
       "      <td>0.789298</td>\n",
       "      <td>0.909222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>0.336695</td>\n",
       "      <td>0.765517</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.567154</td>\n",
       "      <td>0.722022</td>\n",
       "      <td>0.889049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.7892976588628761).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.78\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 02:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.308736</td>\n",
       "      <td>0.765823</td>\n",
       "      <td>0.893372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>0.364556</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.891931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.472524</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.782051282051282).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.812\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 02:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.274800</td>\n",
       "      <td>0.326415</td>\n",
       "      <td>0.789318</td>\n",
       "      <td>0.897695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.377928</td>\n",
       "      <td>0.755418</td>\n",
       "      <td>0.886167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.522278</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.881844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.7893175074183976).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.786\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 02:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.903458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.307484</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>0.916427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.413782</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.916427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.7999999999999999).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.821\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.356600</td>\n",
       "      <td>0.274843</td>\n",
       "      <td>0.729670</td>\n",
       "      <td>0.822767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.443454</td>\n",
       "      <td>0.720848</td>\n",
       "      <td>0.886167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.427956</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.7733333333333333).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.862\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.410755</td>\n",
       "      <td>0.699647</td>\n",
       "      <td>0.877522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.408232</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.891931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.400522</td>\n",
       "      <td>0.776025</td>\n",
       "      <td>0.897695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.77602523659306).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.767\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.312828</td>\n",
       "      <td>0.775087</td>\n",
       "      <td>0.906340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.239911</td>\n",
       "      <td>0.820937</td>\n",
       "      <td>0.906340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.312121</td>\n",
       "      <td>0.843077</td>\n",
       "      <td>0.926513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.8430769230769231).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.834\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.310900</td>\n",
       "      <td>0.253194</td>\n",
       "      <td>0.804290</td>\n",
       "      <td>0.894813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.137700</td>\n",
       "      <td>0.295973</td>\n",
       "      <td>0.770335</td>\n",
       "      <td>0.861671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.427929</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.899135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8042895442359249).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.626\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.312200</td>\n",
       "      <td>0.239229</td>\n",
       "      <td>0.815047</td>\n",
       "      <td>0.914986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.152200</td>\n",
       "      <td>0.297968</td>\n",
       "      <td>0.773770</td>\n",
       "      <td>0.900576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.423150</td>\n",
       "      <td>0.784722</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8150470219435736).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.743\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.333051</td>\n",
       "      <td>0.789644</td>\n",
       "      <td>0.906340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.109500</td>\n",
       "      <td>0.289547</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.537822</td>\n",
       "      <td>0.794702</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.824858757062147).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.738\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.257728</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>0.285289</td>\n",
       "      <td>0.832877</td>\n",
       "      <td>0.912104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.603932</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.887608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.832876712328767).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.793\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.272800</td>\n",
       "      <td>0.283507</td>\n",
       "      <td>0.759804</td>\n",
       "      <td>0.858790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.143900</td>\n",
       "      <td>0.297607</td>\n",
       "      <td>0.790244</td>\n",
       "      <td>0.876081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.569972</td>\n",
       "      <td>0.762463</td>\n",
       "      <td>0.883285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.7902439024390244).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.574\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.296766</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.907781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.316406</td>\n",
       "      <td>0.770318</td>\n",
       "      <td>0.906340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.413013</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.909222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.7835051546391754).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.756\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.337800</td>\n",
       "      <td>0.258566</td>\n",
       "      <td>0.787565</td>\n",
       "      <td>0.881844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.322051</td>\n",
       "      <td>0.796178</td>\n",
       "      <td>0.907781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.391363</td>\n",
       "      <td>0.817337</td>\n",
       "      <td>0.914986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.8173374613003096).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.8109756097560976).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.79\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 02:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.313517</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.889049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.300702</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.478632</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.899135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.8333333333333334).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.686\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.297200</td>\n",
       "      <td>0.370103</td>\n",
       "      <td>0.726644</td>\n",
       "      <td>0.886167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.340311</td>\n",
       "      <td>0.768730</td>\n",
       "      <td>0.897695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.577466</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.900576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.7722772277227723).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.874\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.356600</td>\n",
       "      <td>0.324671</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.889049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.331525</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.887608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.612174</td>\n",
       "      <td>0.691176</td>\n",
       "      <td>0.878963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.746753246753247).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.751\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.326700</td>\n",
       "      <td>0.258348</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.913545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.262168</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.469432</td>\n",
       "      <td>0.759582</td>\n",
       "      <td>0.900576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.807909604519774).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.624\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.227907</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.889049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.362959</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.896254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.405093</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.907781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.8).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.877\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>0.262903</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.909222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.391439</td>\n",
       "      <td>0.758389</td>\n",
       "      <td>0.896254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.544572</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.896254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8108108108108107).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.723\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.305600</td>\n",
       "      <td>0.252421</td>\n",
       "      <td>0.798680</td>\n",
       "      <td>0.912104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.250045</td>\n",
       "      <td>0.797508</td>\n",
       "      <td>0.906340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.553628</td>\n",
       "      <td>0.709924</td>\n",
       "      <td>0.890490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.7986798679867987).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.703\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.323500</td>\n",
       "      <td>0.261954</td>\n",
       "      <td>0.780749</td>\n",
       "      <td>0.881844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.233473</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.899135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.429158</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.912104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.7999999999999999).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.839\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.402263</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.878963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.313210</td>\n",
       "      <td>0.820669</td>\n",
       "      <td>0.914986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.433069</td>\n",
       "      <td>0.788274</td>\n",
       "      <td>0.906340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.8206686930091186).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.742\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.357625</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0.894813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.143500</td>\n",
       "      <td>0.318530</td>\n",
       "      <td>0.796178</td>\n",
       "      <td>0.907781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.501354</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>0.899135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.7961783439490445).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.794\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.278200</td>\n",
       "      <td>0.218176</td>\n",
       "      <td>0.841499</td>\n",
       "      <td>0.920749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.245885</td>\n",
       "      <td>0.803519</td>\n",
       "      <td>0.903458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.541366</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8414985590778099).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.704\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.304300</td>\n",
       "      <td>0.315524</td>\n",
       "      <td>0.775641</td>\n",
       "      <td>0.899135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.338325</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.893372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>0.541072</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.7756410256410257).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.718\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.312700</td>\n",
       "      <td>0.303398</td>\n",
       "      <td>0.750831</td>\n",
       "      <td>0.891931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.144700</td>\n",
       "      <td>0.313612</td>\n",
       "      <td>0.793548</td>\n",
       "      <td>0.907781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.395668</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>0.904899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.7935483870967743).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.84\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.297200</td>\n",
       "      <td>0.275549</td>\n",
       "      <td>0.823881</td>\n",
       "      <td>0.914986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.235878</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.899135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.486232</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.913545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8238805970149253).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.723\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.302300</td>\n",
       "      <td>0.261865</td>\n",
       "      <td>0.781065</td>\n",
       "      <td>0.893372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.140400</td>\n",
       "      <td>0.427270</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.878963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.045300</td>\n",
       "      <td>0.371209</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-132 (score: 0.7820512820512819).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8148148148148149).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.581\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>0.194476</td>\n",
       "      <td>0.839572</td>\n",
       "      <td>0.913545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.352890</td>\n",
       "      <td>0.780645</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.326457</td>\n",
       "      <td>0.809969</td>\n",
       "      <td>0.912104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8395721925133691).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.65\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.273100</td>\n",
       "      <td>0.253949</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.909222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.235288</td>\n",
       "      <td>0.828221</td>\n",
       "      <td>0.919308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.441428</td>\n",
       "      <td>0.786207</td>\n",
       "      <td>0.910663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-88 (score: 0.8282208588957056).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.771\n",
      "model_id='brahimje/roberta-sarcasm-detection', seed=5586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/vocab.json from cache at /home/ray080186/.cache/huggingface/transformers/93bebd4410749f5d4f51af40d0ce91f8551fa116d2327d62c181902d6bfc542b.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/merges.txt from cache at /home/ray080186/.cache/huggingface/transformers/b8385573b031c988fd5e01524c0b67ccce412a56470f2160559df11116fd1a7a.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer.json from cache at /home/ray080186/.cache/huggingface/transformers/31e20f68b315cad181b7fe550df7a3480761f4d1fe14911b39f009937a87b2e1.cfc2bbe974cb2cd49fa76285296a2ded2cbfe78d9ca0705ea6527d434f182f0b\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/special_tokens_map.json from cache at /home/ray080186/.cache/huggingface/transformers/2c06b1ff8b12a239064f76d3cf9fc1755aa78830286820179178f60f487bd917.50c9a6a3342271e7e900bb03520d7f844b78e2b2ef8352a0239b688c7d12bdc6\n",
      "loading file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/tokenizer_config.json from cache at /home/ray080186/.cache/huggingface/transformers/e956e1c03195e2b9ac076e09269765a3af4a7794130cfd4f77f2522a43634ac0.6d717fec0ce330aab3b33f3fab28ae533d11a2c6f01281674e719e15b8a10fa0\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/config.json from cache at /home/ray080186/.cache/huggingface/transformers/09e1612f10fe1811e8affe6d7da564c7439a7be31d085fe75a5ea40353028e40.4bb6b30597006c8e17fb7e74da88181feb35168ab7de0fe5def0ad46c54fec61\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"brahimje/roberta-sarcasm-detection\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/brahimje/roberta-sarcasm-detection/resolve/main/pytorch_model.bin from cache at /home/ray080186/.cache/huggingface/transformers/e0a175450b63a9423f77a6e27574ef2d8e2cc2ba37f3a23156e89004f9a88fd4.ec65ec3772156854ae44ee517647f2ad7ae4e5e4dc8a992cf05fe47716f06ddd\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at brahimje/roberta-sarcasm-detection and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2774\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 132\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 01:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.351100</td>\n",
       "      <td>0.229772</td>\n",
       "      <td>0.835165</td>\n",
       "      <td>0.913545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.172300</td>\n",
       "      <td>0.338225</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.904899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.545073</td>\n",
       "      <td>0.765517</td>\n",
       "      <td>0.902017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-44\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-44/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-88\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-88/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 694\n",
      "  Batch size = 256\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 694 examples in 5552 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Saving model checkpoint to /tmp2/kch/cs263/final_project/models/checkpoint-132\n",
      "Configuration saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/config.json\n",
      "Model weights saved in /tmp2/kch/cs263/final_project/models/checkpoint-132/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /tmp2/kch/cs263/final_project/models/checkpoint-44 (score: 0.8351648351648351).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1400\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/accuracy/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n",
      "Done writing 1400 examples in 11200 bytes /home/ray080186/.cache/huggingface/metrics/f1/default/default_experiment-1-0.arrow.\n",
      "Set __getitem__(key) output type to python objects for no columns  (when key is int or slice) and don't output other (un-formatted) columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.57\n"
     ]
    }
   ],
   "source": [
    "model_ids = [\n",
    "    \"roberta-base\",\n",
    "    \"roberta-large\",\n",
    "    \"cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "    \"cardiffnlp/twitter-roberta-base-irony\",\n",
    "    \"jkhan447/sarcasm-detection-RoBerta-base-CR\",\n",
    "    \"helinivan/english-sarcasm-detector\",\n",
    "    \"brahimje/roberta-sarcasm-detection\",\n",
    "]\n",
    "model_id2f1 = {}\n",
    "k = 10\n",
    "\n",
    "\n",
    "for i, model_id in enumerate(model_ids):\n",
    "    f1s = []\n",
    "    for j in range(k):\n",
    "        seed = j + 5497\n",
    "        f1 = train_and_evaluate(model_id=model_id, seed=seed)\n",
    "        print(\"F1:\", round(f1, 3))\n",
    "        f1s.append(f1)\n",
    "    model_id2f1[model_id] = round(np.mean(f1s), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66813c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"brahimje/roberta-sarcasm-detection\": 0.747\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(model_id2f1, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
